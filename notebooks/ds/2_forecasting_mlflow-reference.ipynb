{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58be1df-50c7-4068-8fd9-7670f9ea72b0",
   "metadata": {},
   "source": [
    "![](../docs/ae_logo.png \"Adapt & Enable\")\n",
    "# AE workshop 2023 - Data science\n",
    "\n",
    "## Part 2 - Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9e858-8579-46e8-8336-51510732cd36",
   "metadata": {},
   "source": [
    "We've explored the data and got a feel for it. Let's move on, and see if we can build a model that predicts the temperature for future points in time! \n",
    "\n",
    "First things first, let's import what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1e4905",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wouter/Documents/Repositories/ae/temp_ws/temp_env_ws/lib/python3.9/site-packages/statsforecast/core.py:21: TqdmExperimentalWarning:\n",
      "\n",
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ../mlruns: File exists\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly import offline\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import *\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    ")\n",
    "import mlflow\n",
    "from pathlib import Path\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "import warnings\n",
    "from tqdm import TqdmExperimentalWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=TqdmExperimentalWarning)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pio.renderers.default = \"iframe\"\n",
    "\n",
    "ae_orange = \"#FD9129\"\n",
    "ae_orange2 = \"#FFD580\"\n",
    "ae_gold = \"#FFD700\"\n",
    "\n",
    "!mkdir ../mlruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28fc53e2-c306-4e6c-9bdf-a6575054a6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:///Users/wouter/Documents/Repositories/ae/temp_ws/workshop_forecasting_2023/notebooks/../mlruns\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(Path(\"../mlruns\").absolute().as_uri())\n",
    "print(mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ab1139-cfa1-4366-9c0d-9ecc71dfb11b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 'ae_forecasting_workshop' already exists.\n",
      "Experiment id: 840895240923856921\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"ae_forecasting_workshop\"\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(\n",
    "        name=experiment_name,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "print(f\"Experiment id: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29a379",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2eae3f",
   "metadata": {},
   "source": [
    "Let's load the data we saved from the previous step. If the next cell fails, *make sure you ran through the entire [EDA notebook](./1_EDA.ipynb)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6174f665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1750-01-01</th>\n",
       "      <td>3.034</td>\n",
       "      <td>3.574</td>\n",
       "      <td>1</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750-02-01</th>\n",
       "      <td>3.083</td>\n",
       "      <td>3.702</td>\n",
       "      <td>2</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750-03-01</th>\n",
       "      <td>5.626</td>\n",
       "      <td>3.076</td>\n",
       "      <td>3</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750-04-01</th>\n",
       "      <td>8.490</td>\n",
       "      <td>2.451</td>\n",
       "      <td>4</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750-05-01</th>\n",
       "      <td>11.573</td>\n",
       "      <td>2.072</td>\n",
       "      <td>5</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            temperature  uncertainty  month  year\n",
       "date                                             \n",
       "1750-01-01        3.034        3.574      1  1750\n",
       "1750-02-01        3.083        3.702      2  1750\n",
       "1750-03-01        5.626        3.076      3  1750\n",
       "1750-04-01        8.490        2.451      4  1750\n",
       "1750-05-01       11.573        2.072      5  1750"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/cleaned.csv\")\n",
    "df.index = df.date\n",
    "df = df.drop(columns=[\"date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434cff69-20d6-4a58-acbc-3027ea646f3e",
   "metadata": {},
   "source": [
    "Alright, looks good! Let's get started. \n",
    "\n",
    "### Train-val-test split\n",
    "\n",
    "First, as with any machine learning algorithm, we'll want to define on which data we'll **train** the model, and which part we'll use to **validate** whether our model is any good. In addition, we should define a hold-out **test** set. Validation splits can be used to tweak our model (and its hyperparameters), but the test set serves to yield a final benchmark for our model's performance. We'll skip the test set for this workshop, just this once.\n",
    "\n",
    "We'll do this in a simple way, setting aside the final segments of the data for validation. It's good to be aware of slightly more complex strategies, such as the use of [sklearn's TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html). Since regular randomized cross-validation won't work for time series (you can figure out why, right?), other validation strategies were cooked up, such as *rolling window cross-validation* or *walk-forward validation*. The latter is implemented in `TimeSeriesSplit`.\n",
    "\n",
    "![TimeSeriesSplit](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_013.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb7b62d-9e0b-4bba-a492-9fa6ab0404c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to generate splits\n",
    "def train_val_test_split(data: pd.DataFrame, train=0.7, val=0.15, test=0.15):\n",
    "    # Make sure our splits add up\n",
    "    total = train + test + val\n",
    "    if not total == 1:\n",
    "        print(\n",
    "            f\"Train, validation and test portions don't add up to 1! Currently the total is{total}. Rebalancing.\"\n",
    "        )\n",
    "        train /= total\n",
    "        val /= total\n",
    "        test /= total\n",
    "\n",
    "    # Calculate row counts\n",
    "    n_rows = len(data)\n",
    "    train_rows = int(train * n_rows)\n",
    "    val_rows = int(val * n_rows)\n",
    "    test_rows = n_rows - (train_rows + val_rows)\n",
    "\n",
    "    # Slice up the data\n",
    "    train_data = data.iloc[:train_rows]\n",
    "    val_data = data.iloc[train_rows : train_rows + val_rows]\n",
    "    test_data = data.iloc[train_rows + val_rows :]\n",
    "\n",
    "    print(\n",
    "        f\"Training split:   {train_rows} data points\\tfrom {train_data.index.min()} till {train_data.index.max()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Validation split: {val_rows} data points\\tfrom {val_data.index.min()} till {val_data.index.max()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Test split:       {test_rows} data points\\tfrom {test_data.index.min()} till {test_data.index.max()}\"\n",
    "    )\n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3320db99-46b8-4cd5-8b7d-4c6734f6ecde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split:   2544 data points\tfrom 1750-01-01 till 1962-12-01\n",
      "Validation split: 636 data points\tfrom 1963-01-01 till 2015-12-01\n",
      "Test split:       0 data points\tfrom nan till nan\n"
     ]
    }
   ],
   "source": [
    "train, val, test = train_val_test_split(df, train=0.8, val=0.2, test=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9846cc1",
   "metadata": {},
   "source": [
    "Here, I'll also define helper functions. The first one, `forecast_metrics`, can give us basic time series forecasting performance metrics. We'll use this later on to evaluate our models. The second, `visualize_metrics`, will help us visualize the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34305487",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to give us some basic time series forecasting performance metrics\n",
    "def forecast_metrics(y_true, y_pred):\n",
    "    # Collect metrics in a dictionary\n",
    "    metrics = {}\n",
    "\n",
    "    metrics[\"MSE\"] = mean_squared_error(y_true, y_pred)\n",
    "    metrics[\"MAE\"] = mean_absolute_error(y_true, y_pred)\n",
    "    metrics[\"RMSE\"] = np.sqrt(metrics[\"MSE\"])\n",
    "    metrics[\"R-squared\"] = r2_score(y_true, y_pred)\n",
    "    metrics[\"EV\"] = explained_variance_score(y_true, y_pred)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98edbc75",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to visualize performance\n",
    "def visualize_metrics(results_df: pd.DataFrame, baseline=True):\n",
    "    # Don't mess with our original data\n",
    "    viz_df = results_df.copy()\n",
    "\n",
    "    # Get rid of baseline if not requested\n",
    "    if not baseline:\n",
    "        del viz_df[\"HistoricAverage\"]\n",
    "\n",
    "    # Create subplot grid with one row per metric\n",
    "    fig = make_subplots(rows=1, cols=viz_df.shape[0], horizontal_spacing=0.1)\n",
    "\n",
    "    # Loop through each row and add a bar chart to the corresponding subplot\n",
    "    for idx, (name, row) in enumerate(viz_df.iterrows()):\n",
    "        fig.add_trace(go.Bar(x=row.index, y=row.values, name=name), row=1, col=idx + 1)\n",
    "        # Give the child a name\n",
    "        fig.update_yaxes(title_text=name, row=1, col=idx + 1)\n",
    "\n",
    "    # Update layout and show the figure\n",
    "    fig.update_layout(\n",
    "        height=400, width=1200, title=\"Model comparison\", showlegend=False\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acca41b5",
   "metadata": {},
   "source": [
    "### 1. Statistical modelling: ARIMA (and friends)\n",
    "\n",
    "We'll first try and fit an **A**uto**r**egressive **I**ntegrated **M**oving **A**verage model. That's a mouthful, we know. This statistical model is quite common in the industry (e.g., in stock price forecasting).\n",
    "\n",
    "* It's *autoregressive* because it uses past values of a variable to predict its future values (i.e., it regresses onto itself).\n",
    "* It uses a *moving average* of the past errors to predict future errors.\n",
    "* Finally, it's *integrated* in the sense that it uses differencing to make the data stationary -- that is, it removes trends and seasonal patterns to try and obtain a stationary signal.\n",
    "\n",
    "Let's fit one! Here, we will use a class called `AutoARIMA`, which automatically finds the best ARIMA model based on an information criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0cf6f06",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Many of these packages are picky about the column names, so here's a helper function to prep the data\n",
    "def prep_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={\"date\": \"ds\", \"temperature\": \"y\"})\n",
    "    df[\"unique_id\"] = 1\n",
    "    df = df[[\"unique_id\", \"ds\", \"y\"]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361bf7d7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sf = prep_df(train)\n",
    "val_sf = prep_df(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b392385a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting models:   0%|                                                                                                                             | 0/2 [00:00<?, ?it/s]/Users/wouter/Documents/Repositories/ae/temp_ws/temp_env_ws/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning:\n",
      "\n",
      "Setuptools is replacing distutils.\n",
      "\n",
      "Fitting models: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:03<00:00, 31.99s/it]\n"
     ]
    }
   ],
   "source": [
    "season_length = 12  # Monthly data\n",
    "horizon = len(val)  # Predict the length of the validation df\n",
    "\n",
    "# Include the models you imported\n",
    "models = [\n",
    "    # This is a baseline model\n",
    "    HistoricAverage(),\n",
    "    # This is a better model\n",
    "    AutoARIMA(season_length=season_length),\n",
    "    # YOU CAN ADD MODELS HERE\n",
    "]\n",
    "\n",
    "# We'll store metrics here\n",
    "metrics = dict()\n",
    "\n",
    "# We'll keep track of our forecasts for visualization\n",
    "forecasts = dict()\n",
    "\n",
    "# Let's loop through the models\n",
    "for m in tqdm(models, desc=\"Fitting models\"):\n",
    "    # Start an MLflow run for each model\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=str(m)):\n",
    "        # Instantiate the StatsForecast class as sf\n",
    "        model = StatsForecast(df=train_sf, models=[m], freq=\"MS\", n_jobs=-1)\n",
    "\n",
    "        # Forecast for the defined horizon\n",
    "        forecasts[str(m)] = model.forecast(horizon)\n",
    "\n",
    "        # Let's calculate and store metrics for every one of them\n",
    "        metrics[str(m)] = forecast_metrics(val.temperature, forecasts[str(m)][str(m)])\n",
    "\n",
    "        # Log the metrics\n",
    "        mlflow.log_metrics(metrics[str(m)])\n",
    "\n",
    "        # Log the model TODO: this is probably wrong, use pyfunc instead\n",
    "        mlflow.sklearn.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "678eb3db",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HistoricAverage':                   ds  HistoricAverage\n",
       " unique_id                            \n",
       " 1         1963-01-01         8.203653\n",
       " 1         1963-02-01         8.203653\n",
       " 1         1963-03-01         8.203653\n",
       " 1         1963-04-01         8.203653\n",
       " 1         1963-05-01         8.203653\n",
       " ...              ...              ...\n",
       " 1         2015-08-01         8.203653\n",
       " 1         2015-09-01         8.203653\n",
       " 1         2015-10-01         8.203653\n",
       " 1         2015-11-01         8.203653\n",
       " 1         2015-12-01         8.203653\n",
       " \n",
       " [636 rows x 2 columns],\n",
       " 'AutoARIMA':                   ds  AutoARIMA\n",
       " unique_id                      \n",
       " 1         1963-01-01   2.947784\n",
       " 1         1963-02-01   3.428498\n",
       " 1         1963-03-01   5.249260\n",
       " 1         1963-04-01   8.438313\n",
       " 1         1963-05-01  11.231355\n",
       " ...              ...        ...\n",
       " 1         2015-08-01  13.825442\n",
       " 1         2015-09-01  12.074201\n",
       " 1         2015-10-01   9.428504\n",
       " 1         2015-11-01   6.075994\n",
       " 1         2015-12-01   3.790407\n",
       " \n",
       " [636 rows x 2 columns]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386351ef",
   "metadata": {},
   "source": [
    "As you can see, the forecast dict now has model-forecast mappings, corresponding to the validation dates.\n",
    "\n",
    "If you add another type of model to the list, they'll show up here as extra keys. **Have a look [here](https://github.com/Nixtla/statsforecast) if you're curious, or just want to play around.**\n",
    "\n",
    "Before we calculate performance metrics, let's visualize our predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b920cf8e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_13.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_plots = []\n",
    "prediction_plots = []\n",
    "\n",
    "# Plot our training data\n",
    "base_plots.append(\n",
    "    go.Scatter(\n",
    "        x=train.index,\n",
    "        y=train.temperature,\n",
    "        mode=\"lines\",\n",
    "        name=\"training\",\n",
    "        line=dict(color=ae_gold),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot our observed validation values\n",
    "base_plots.append(\n",
    "    go.Scatter(\n",
    "        x=val.index,\n",
    "        y=val.temperature,\n",
    "        mode=\"lines\",\n",
    "        name=\"observed\",\n",
    "        line=dict(color=\"grey\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot our ARIMA prediction\n",
    "for model, forecast in forecasts.items():\n",
    "    prediction_plots.append(\n",
    "        go.Scatter(\n",
    "            x=forecast.ds, y=forecast[model], mode=\"lines\", name=f\"predicted_{model}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Display everything together\n",
    "fig = go.Figure(data=base_plots + prediction_plots)\n",
    "fig.update_layout(title=\"Forecasting in action 🚀\")\n",
    "\n",
    "fig.show(renderer=\"iframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7331d7e",
   "metadata": {},
   "source": [
    "Not bad! Let's calculate some performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1cb9123",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HistoricAverage</th>\n",
       "      <th>AutoARIMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17.998435</td>\n",
       "      <td>0.385591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>3.812531</td>\n",
       "      <td>0.494046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>4.242456</td>\n",
       "      <td>0.620960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>-0.042374</td>\n",
       "      <td>0.977669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           HistoricAverage  AutoARIMA\n",
       "MSE              17.998435   0.385591\n",
       "MAE               3.812531   0.494046\n",
       "RMSE              4.242456   0.620960\n",
       "R-squared        -0.042374   0.977669\n",
       "EV                0.000000   0.986248"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(metrics)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebaf0253-31e5-4a2d-8e6b-916007ee3c49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1220px\"\n",
       "    height=\"420\"\n",
       "    src=\"iframe_figures/figure_15.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_metrics(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee9e1f-0be4-4a11-9d35-7030dc4bb591",
   "metadata": {},
   "source": [
    "Clearly, the ARIMA approach blows the baseline model out of the water. Good! Now let's try another model: Facebook's [Prophet](https://facebook.github.io/prophet/)!\n",
    "\n",
    "### 2. Prophet\n",
    "\n",
    "> Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.\n",
    "\n",
    "Prophet is a special case of the Generalized Additive Model. Whereas ARIMA tries to build a formula for future values as a function of past values, Prophet tries to detect “change points”; you can think of Prophet as curve-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54e3d48d-3750-4a00-9cd6-27a0442dcb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b63ebb58-7ea8-4f96-9577-ebd9208cde77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -148.717\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       6533.31   0.000703434       94.7922      0.9175      0.9175      122   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       6535.78     0.0030299       516.128      0.4554           1      237   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299        6536.9   0.000130725       87.3566      0.8909      0.8909      349   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     313       6536.91    1.2776e-05       59.2699   2.184e-07       0.001      413  LS failed, Hessian reset \n",
      "     349       6536.91   1.19153e-05       75.2354   1.778e-07       0.001      495  LS failed, Hessian reset \n",
      "     363       6536.91   4.61266e-07       55.4866       0.217           1      515   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "# We'll use the same train and val dataframes as before\n",
    "model = Prophet()\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"Prophet\"):\n",
    "    # Fit the model\n",
    "    model.fit(train_sf)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.prophet.log_model(model, artifact_path=\"prophet\")\n",
    "\n",
    "    # Forecast for the defined horizon\n",
    "    future = model.make_future_dataframe(periods=horizon, freq=\"MS\")\n",
    "    forecast = model.predict(future)[-len(val) :]\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics[\"Prophet\"] = forecast_metrics(val.temperature, forecast.yhat)\n",
    "\n",
    "    # Log the metrics\n",
    "    mlflow.log_metrics(metrics[\"Prophet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a5bc69d-ce6c-4d1b-9296-c2d15afaf8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_18.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot prophet's prediction\n",
    "prophet_plot = [\n",
    "    go.Scatter(x=forecast.ds, y=forecast.yhat, mode=\"lines\", name=\"predicted_prophet\")\n",
    "]\n",
    "\n",
    "# Display\n",
    "fig = go.Figure(data=base_plots + prediction_plots + prophet_plot)\n",
    "fig.update_layout(title=\"Forecasting in action (part 2) 🚀\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8adef50d-aca1-4223-9848-b36cf26a1310",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HistoricAverage</th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>Prophet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17.998435</td>\n",
       "      <td>0.385591</td>\n",
       "      <td>0.199542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>3.812531</td>\n",
       "      <td>0.494046</td>\n",
       "      <td>0.357879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>4.242456</td>\n",
       "      <td>0.620960</td>\n",
       "      <td>0.446701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>-0.042374</td>\n",
       "      <td>0.977669</td>\n",
       "      <td>0.988444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986248</td>\n",
       "      <td>0.988740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           HistoricAverage  AutoARIMA   Prophet\n",
       "MSE              17.998435   0.385591  0.199542\n",
       "MAE               3.812531   0.494046  0.357879\n",
       "RMSE              4.242456   0.620960  0.446701\n",
       "R-squared        -0.042374   0.977669  0.988444\n",
       "EV                0.000000   0.986248  0.988740"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(metrics)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e33457bb-a8cc-44db-a12a-c391d50b5234",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1220px\"\n",
       "    height=\"420\"\n",
       "    src=\"iframe_figures/figure_20.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_metrics(results_df, baseline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc0198-ab3e-46a9-949a-ccd3f9c361da",
   "metadata": {
    "tags": []
   },
   "source": [
    "Interestingly, it appears that Prophet has a small edge in performance. Inspect the plot: it looks like, as time progresses, the ARIMA model is content to just keep oscillating around a certain value, and fails to capture the upwards trend well. Prophet does better in predicting the later time points. Get rid of the baseline model (HistoricAverage) to get a better look.\n",
    "\n",
    "For the hell of it, let's go bonkers with some out-of-the-box deep learning: [NeuralProphet](https://neuralprophet.com). Overkill, yay!\n",
    "\n",
    "### 3. NeuralProphet\n",
    "\n",
    "> NeuralProphet is an easy to learn framework for interpretable time series forecasting. NeuralProphet is built on PyTorch and combines Neural Network and traditional time-series algorithms, inspired by Facebook Prophet and AR-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6415aba8-15d6-42ab-a7b9-d0cf75333102",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /var/folders/wy/blzz4kvd2mxb06z0tj0w60b00000gp/T/tmpn9w5wm84\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /var/folders/wy/blzz4kvd2mxb06z0tj0w60b00000gp/T/tmpn9w5wm84/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "from neuralprophet import NeuralProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54ba0c46-7ba6-4503-b852-6d716e25fcce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to 91.392% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to 91.392% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Dataframe freq automatically defined as MS\n",
      "INFO:NP.df_utils:Dataframe freq automatically defined as MS\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO:NP.utils:Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO:NP.utils:Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "INFO:NP.config:Auto-set batch_size to 32\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 147\n",
      "INFO:NP.config:Auto-set epochs to 147\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/wouter/Documents/Repositories/ae/temp_ws/temp_env_ws/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n",
      "\n",
      "MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "\n",
      "\n",
      "WARNING:py.warnings:/Users/wouter/Documents/Repositories/ae/temp_ws/temp_env_ws/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n",
      "\n",
      "MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "\n",
      "\n",
      "WARNING - (NP.config.set_lr_finder_args) - Learning rate finder: The number of batches (80) is too small than the required number for the learning rate finder (235). The results might not be optimal.\n",
      "WARNING:NP.config:Learning rate finder: The number of batches (80) is too small than the required number for the learning rate finder (235). The results might not be optimal.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc19968392fe40b3af5eeb84e67deaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fd33d6f55b47fd9f78fe808af5b1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to 91.392% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to 91.392% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - MS\n",
      "INFO:NP.df_utils:Defined frequency is equal to major frequency - MS\n",
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO:NP.df_utils:Returning df with no ID column\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to 91.447% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to 91.447% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - MS\n",
      "INFO:NP.df_utils:Defined frequency is equal to major frequency - MS\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to 91.447% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to 91.447% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - MS\n",
      "INFO:NP.df_utils:Defined frequency is equal to major frequency - MS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e143d38070c46fcb171eeeebe4ba5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 80it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO:NP.df_utils:Returning df with no ID column\n"
     ]
    }
   ],
   "source": [
    "# Adapt our training data to fit the expected format\n",
    "train_neural = train_sf.drop(columns=[\"unique_id\"])\n",
    "\n",
    "# Initialize model\n",
    "overkill_model = NeuralProphet()\n",
    "\n",
    "# Start a new run\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"Neural Prophet\"):\n",
    "    # Fit the model\n",
    "    overkill_model.fit(train_neural)\n",
    "\n",
    "    # Forecast for the defined horizon\n",
    "    future = overkill_model.make_future_dataframe(\n",
    "        train_neural, periods=len(val), n_historic_predictions=len(train_neural)\n",
    "    )\n",
    "    forecast = overkill_model.predict(future)[-len(val) :]\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics[\"Neural Prophet\"] = forecast_metrics(val.temperature, forecast.yhat1)\n",
    "\n",
    "    # Log the metrics\n",
    "    mlflow.log_metrics(metrics[\"Neural Prophet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0323f185-23e3-4f1d-bed3-c6c8e897c56b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_23.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot prophet's prediction\n",
    "neural_plot = [\n",
    "    go.Scatter(\n",
    "        x=forecast.ds, y=forecast.yhat1, mode=\"lines\", name=\"predicted_neural_prophet\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Display\n",
    "fig = go.Figure(data=base_plots + prediction_plots + neural_plot + prophet_plot)\n",
    "fig.update_layout(title=\"Forecasting in action (part 2) 🚀\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc6730-172d-46e6-8cb8-1e16d01528c5",
   "metadata": {},
   "source": [
    "Looks pretty similar, right? Hard to tell if we gained anything. What does the data tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38b7610d-f01c-471d-8428-5d3f37479a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HistoricAverage</th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>Prophet</th>\n",
       "      <th>Neural Prophet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17.998435</td>\n",
       "      <td>0.385591</td>\n",
       "      <td>0.199542</td>\n",
       "      <td>0.191100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>3.812531</td>\n",
       "      <td>0.494046</td>\n",
       "      <td>0.357879</td>\n",
       "      <td>0.351498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>4.242456</td>\n",
       "      <td>0.620960</td>\n",
       "      <td>0.446701</td>\n",
       "      <td>0.437150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>-0.042374</td>\n",
       "      <td>0.977669</td>\n",
       "      <td>0.988444</td>\n",
       "      <td>0.988933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986248</td>\n",
       "      <td>0.988740</td>\n",
       "      <td>0.989061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           HistoricAverage  AutoARIMA   Prophet  Neural Prophet\n",
       "MSE              17.998435   0.385591  0.199542        0.191100\n",
       "MAE               3.812531   0.494046  0.357879        0.351498\n",
       "RMSE              4.242456   0.620960  0.446701        0.437150\n",
       "R-squared        -0.042374   0.977669  0.988444        0.988933\n",
       "EV                0.000000   0.986248  0.988740        0.989061"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"Neural Prophet\"] = forecast_metrics(val.temperature, forecast.yhat1)\n",
    "results_df = pd.DataFrame(metrics)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c41e820f-0144-4d40-b258-94c4c0323852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1220px\"\n",
       "    height=\"420\"\n",
       "    src=\"iframe_figures/figure_25.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_metrics(results_df, baseline=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d25b2d-de0a-47ee-b0eb-3c0d5715bc41",
   "metadata": {},
   "source": [
    "You'll have to zoom in again, but it looks like we reduced our error yet a little more. Worth it? Depends on the time and compute we have at hand. The AutoARIMA model was actually quite expensive on both fronts. Prophet, in comparison, did fairly well! NeuralProphet did even better, but took a while longer to fit. Use the right tool for the right job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b481a6-41ae-4c2a-9662-6307bcd3ae0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74acd39-9de7-4590-a35c-79cc0b90bd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324390a-2e48-43ec-aa35-92d9f5a5cac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp_env_ws",
   "language": "python",
   "name": "temp_env_ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
