{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58be1df-50c7-4068-8fd9-7670f9ea72b0",
   "metadata": {},
   "source": [
    "![](../docs/ae_logo.png \"Adapt & Enable\")\n",
    "# AE workshop 2023 - Data science\n",
    "\n",
    "## Part 2 - Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9e858-8579-46e8-8336-51510732cd36",
   "metadata": {},
   "source": [
    "We've explored the data and got a feel for it. Let's move on, and see if we can build a model that predicts the temperature for future points in time! \n",
    "\n",
    "First things first, let's import what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1e4905",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wouter/Documents/Repositories/ae/temp_ws/temp_env_ws/lib/python3.9/site-packages/statsforecast/core.py:21: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import *\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    ")\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import warnings\n",
    "from tqdm import TqdmExperimentalWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=TqdmExperimentalWarning)\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "ae_orange = \"#FD9129\"\n",
    "ae_orange2 = \"#FFD580\"\n",
    "ae_gold = \"#FFD700\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29a379",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2eae3f",
   "metadata": {},
   "source": [
    "Let's load the data we saved from the previous step. If the next cell fails, *make sure you ran through the entire [EDA notebook](./1_EDA.ipynb)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6174f665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1750-01-01</th>\n",
       "      <td>3.034</td>\n",
       "      <td>3.574</td>\n",
       "      <td>1</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750-02-01</th>\n",
       "      <td>3.083</td>\n",
       "      <td>3.702</td>\n",
       "      <td>2</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750-03-01</th>\n",
       "      <td>5.626</td>\n",
       "      <td>3.076</td>\n",
       "      <td>3</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750-04-01</th>\n",
       "      <td>8.490</td>\n",
       "      <td>2.451</td>\n",
       "      <td>4</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750-05-01</th>\n",
       "      <td>11.573</td>\n",
       "      <td>2.072</td>\n",
       "      <td>5</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            temperature  uncertainty  month  year\n",
       "date                                             \n",
       "1750-01-01        3.034        3.574      1  1750\n",
       "1750-02-01        3.083        3.702      2  1750\n",
       "1750-03-01        5.626        3.076      3  1750\n",
       "1750-04-01        8.490        2.451      4  1750\n",
       "1750-05-01       11.573        2.072      5  1750"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/cleaned.csv\")\n",
    "df.index = df.date\n",
    "df = df.drop(columns=[\"date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434cff69-20d6-4a58-acbc-3027ea646f3e",
   "metadata": {},
   "source": [
    "Alright, looks good! Let's get started. \n",
    "\n",
    "### Train-val-test split\n",
    "\n",
    "First, as with any machine learning algorithm, we'll want to define on which data we'll **train** the model, and which part we'll use to **validate** whether our model is any good. In addition, we should define a hold-out **test** set. Validation splits can be used to tweak our model (and its hyperparameters), but the test set serves to yield a final benchmark for our model's performance. We'll skip the test set for this workshop, just this once.\n",
    "\n",
    "We'll do this in a simple way, setting aside the final segments of the data for validation. It's good to be aware of slightly more complex strategies, such as the use of [sklearn's TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html). Since regular randomized cross-validation won't work for time series (you can figure out why, right?), other validation strategies were cooked up, such as *rolling window cross-validation* or *walk-forward validation*. The latter is implemented in `TimeSeriesSplit`.\n",
    "\n",
    "![TimeSeriesSplit](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_013.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb7b62d-9e0b-4bba-a492-9fa6ab0404c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to generate splits\n",
    "def train_val_test_split(data: pd.DataFrame, train=0.7, val=0.15, test=0.15):\n",
    "    # Make sure our splits add up\n",
    "    total = train + test + val\n",
    "    if not total == 1:\n",
    "        print(\n",
    "            f\"Train, validation and test portions don't add up to 1! Currently the total is{total}. Rebalancing.\"\n",
    "        )\n",
    "        train /= total\n",
    "        val /= total\n",
    "        test /= total\n",
    "\n",
    "    # Calculate row counts\n",
    "    n_rows = len(data)\n",
    "    train_rows = int(train * n_rows)\n",
    "    val_rows = int(val * n_rows)\n",
    "    test_rows = n_rows - (train_rows + val_rows)\n",
    "\n",
    "    # Slice up the data\n",
    "    train_data = data.iloc[:train_rows]\n",
    "    val_data = data.iloc[train_rows : train_rows + val_rows]\n",
    "    test_data = data.iloc[train_rows + val_rows :]\n",
    "\n",
    "    print(\n",
    "        f\"Training split:   {train_rows} data points\\tfrom {train_data.index.min()} till {train_data.index.max()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Validation split: {val_rows} data points\\tfrom {val_data.index.min()} till {val_data.index.max()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Test split:       {test_rows} data points\\tfrom {test_data.index.min()} till {test_data.index.max()}\"\n",
    "    )\n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3320db99-46b8-4cd5-8b7d-4c6734f6ecde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split:   2544 data points\tfrom 1750-01-01 till 1962-12-01\n",
      "Validation split: 636 data points\tfrom 1963-01-01 till 2015-12-01\n",
      "Test split:       0 data points\tfrom nan till nan\n"
     ]
    }
   ],
   "source": [
    "train, val, test = train_val_test_split(df, train=0.8, val=0.2, test=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ec77a-28c9-4d80-9e91-e1c3cc20b230",
   "metadata": {},
   "source": [
    "### 1. Statistical modelling: ARIMA (and friends)\n",
    "\n",
    "We'll first try and fit an **A**uto**r**egressive **I**ntegrated **M**oving **A**verage model. That's a mouthful, we know. This statistical model is quite common in the industry (e.g., in stock price forecasting). \n",
    "\n",
    "* It's *autoregressive* because it uses past values of a variable to predict its future values (i.e., it regresses onto itself). \n",
    "* It uses a *moving average* of the past errors to predict future errors. \n",
    "* Finally, it's *integrated* in the sense that it uses differencing to make the data stationary -- that is, it removes trends and seasonal patterns to try and obtain a stationary signal.\n",
    "\n",
    "Let's fit one! Here, we will use a class called `AutoARIMA`, which automatically finds the best ARIMA model based on an information criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac65744-52f4-4c5e-baca-0db4453981a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Many of these packages are picky about the column names, so here's a helper function to prep the data\n",
    "def prep_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={\"date\": \"ds\", \"temperature\": \"y\"})\n",
    "    df[\"unique_id\"] = 1\n",
    "    df = df[[\"unique_id\", \"ds\", \"y\"]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fb0cfac-6d6e-4c53-a380-a3b962285848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sf = prep_df(train)\n",
    "val_sf = prep_df(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6142855-fc38-438c-9990-bbf54d623fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "season_length = 12  # Monthly data\n",
    "horizon = len(val)  # Predict the length of the validation df\n",
    "\n",
    "# Include the models you imported\n",
    "models = [\n",
    "    # This is a baseline model\n",
    "    HistoricAverage(),\n",
    "    # This is a better model\n",
    "    AutoARIMA(season_length=season_length),\n",
    "    # YOU CAN ADD MODELS HERE\n",
    "]\n",
    "\n",
    "# Instantiate the StatsForecast class as sf\n",
    "sf = StatsForecast(df=train_sf, models=models, freq=\"MS\", n_jobs=-1)\n",
    "\n",
    "# Forecast for the defined horizon\n",
    "forecast = sf.forecast(horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e2549-e8c6-4b5e-a89b-dc9c7f23c1d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66939cb8-c5f9-4063-a620-1ff8b0d49538",
   "metadata": {},
   "source": [
    "As you can see, the forecast data frame now has an `AutoARIMA` column with forecast values, corresponding to the validation dates.\n",
    "\n",
    "If you add another type of model to the list, they'll show up here as extra columns. **Have a look [here](https://github.com/Nixtla/statsforecast) if you're curious, or just want to play around.**\n",
    "\n",
    "Before we calculate performance metrics, let's visualize our predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd70af-effb-4819-9da5-bb49bf9bd185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_plots = []\n",
    "prediction_plots = []\n",
    "\n",
    "# Plot our training data\n",
    "base_plots.append(\n",
    "    go.Scatter(\n",
    "        x=train.index,\n",
    "        y=train.temperature,\n",
    "        mode=\"lines\",\n",
    "        name=\"training\",\n",
    "        line=dict(color=ae_gold),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot our observed validation values\n",
    "base_plots.append(\n",
    "    go.Scatter(\n",
    "        x=val.index,\n",
    "        y=val.temperature,\n",
    "        mode=\"lines\",\n",
    "        name=\"observed\",\n",
    "        line=dict(color=\"grey\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot our ARIMA prediction\n",
    "for model in forecast.columns[1:]:\n",
    "    prediction_plots.append(\n",
    "        go.Scatter(\n",
    "            x=forecast.ds, y=forecast[model], mode=\"lines\", name=f\"predicted_{model}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Display\n",
    "fig = go.Figure(data=base_plots + prediction_plots)\n",
    "fig.update_layout(title=\"Forecasting in action ðŸš€\")\n",
    "\n",
    "py.iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675cd3b4-396d-44df-b0a0-58f112c3e7f4",
   "metadata": {},
   "source": [
    "Not bad! Let's calculate some performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22dcea8-a992-479a-8cc7-366aa8e9778a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to give us some basic time series forecasting performance metrics\n",
    "def forecast_metrics(y_true, y_pred):\n",
    "    # Collect metrics in a dictionary\n",
    "    metrics = {}\n",
    "\n",
    "    metrics[\"MSE\"] = mean_squared_error(y_true, y_pred)\n",
    "    metrics[\"MAE\"] = mean_absolute_error(y_true, y_pred)\n",
    "    metrics[\"RMSE\"] = np.sqrt(metrics[\"MSE\"])\n",
    "    metrics[\"R-squared\"] = r2_score(y_true, y_pred)\n",
    "    metrics[\"EV\"] = explained_variance_score(y_true, y_pred)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f7aab-1ea8-41e6-9990-b6f9f0be136b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These models were implemented\n",
    "models = forecast.columns[1:]\n",
    "\n",
    "# Let's calculate and store metrics for every one of them\n",
    "results = dict()\n",
    "for model in models:\n",
    "    results[model] = forecast_metrics(val.temperature, forecast[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16297f9-69b5-4dad-95ad-af11058e9137",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f486f-14df-4fc1-9380-57dafcc14d00",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to visualize performance\n",
    "def visualize_metrics(results_df: pd.DataFrame, baseline=True):\n",
    "    # Don't mess with our original data\n",
    "    viz_df = results_df.copy()\n",
    "\n",
    "    # Get rid of baseline if not requested\n",
    "    if not baseline:\n",
    "        del viz_df[\"HistoricAverage\"]\n",
    "\n",
    "    # Create subplot grid with one row per metric\n",
    "    fig = make_subplots(rows=1, cols=viz_df.shape[0], horizontal_spacing=0.1)\n",
    "\n",
    "    # Loop through each row and add a bar chart to the corresponding subplot\n",
    "    for idx, (name, row) in enumerate(viz_df.iterrows()):\n",
    "        fig.add_trace(go.Bar(x=row.index, y=row.values, name=name), row=1, col=idx + 1)\n",
    "        # Give the child a name\n",
    "        fig.update_yaxes(title_text=name, row=1, col=idx + 1)\n",
    "\n",
    "    # Update layout and show the figure\n",
    "    fig.update_layout(\n",
    "        height=400, width=1200, title=\"Model comparison\", showlegend=False\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf0253-31e5-4a2d-8e6b-916007ee3c49",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_metrics(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee9e1f-0be4-4a11-9d35-7030dc4bb591",
   "metadata": {},
   "source": [
    "Clearly, the ARIMA approach blows the baseline model out of the water. Good! Now let's try another model: Facebook's [Prophet](https://facebook.github.io/prophet/)!\n",
    "\n",
    "### 2. Prophet\n",
    "\n",
    "> Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.\n",
    "\n",
    "Prophet is a special case of the Generalized Additive Model. Whereas ARIMA tries to build a formula for future values as a function of past values, Prophet tries to detect â€œchange pointsâ€; you can think of Prophet as curve-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3d48d-3750-4a00-9cd6-27a0442dcb4b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ebb58-7ea8-4f96-9577-ebd9208cde77",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Prophet()\n",
    "model.fit(train_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538da35-dfdc-461e-a3ff-275d11fe95da",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "future = model.make_future_dataframe(periods=len(val), freq=\"MS\")\n",
    "forecast = model.predict(future)[-len(val) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5bc69d-ce6c-4d1b-9296-c2d15afaf8cb",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot prophet's prediction\n",
    "prophet_plot = [\n",
    "    go.Scatter(x=forecast.ds, y=forecast.yhat, mode=\"lines\", name=\"predicted_prophet\")\n",
    "]\n",
    "\n",
    "# Display\n",
    "fig = go.Figure(data=base_plots + prediction_plots + prophet_plot)\n",
    "fig.update_layout(title=\"Forecasting in action (part 2) ðŸš€\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adef50d-aca1-4223-9848-b36cf26a1310",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results[\"Prophet\"] = forecast_metrics(val.temperature, forecast.yhat)\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33457bb-a8cc-44db-a12a-c391d50b5234",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_metrics(results_df, baseline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc0198-ab3e-46a9-949a-ccd3f9c361da",
   "metadata": {
    "tags": []
   },
   "source": [
    "Interestingly, it appears that Prophet has a small edge in performance. Inspect the plot: it looks like, as time progresses, the ARIMA model is content to just keep oscillating around a certain value, and fails to capture the upwards trend well. Prophet does better in predicting the later time points. Get rid of the baseline model (HistoricAverage) to get a better look.\n",
    "\n",
    "For the hell of it, let's go bonkers with some out-of-the-box deep learning: [NeuralProphet](https://neuralprophet.com). Overkill, yay!\n",
    "\n",
    "### 3. NeuralProphet\n",
    "\n",
    "> NeuralProphet is an easy to learn framework for interpretable time series forecasting. NeuralProphet is built on PyTorch and combines Neural Network and traditional time-series algorithms, inspired by Facebook Prophet and AR-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6415aba8-15d6-42ab-a7b9-d0cf75333102",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from neuralprophet import NeuralProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba0c46-7ba6-4503-b852-6d716e25fcce",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_neural = train_sf.drop(columns=[\"unique_id\"])\n",
    "overkill_model = NeuralProphet()\n",
    "overkill_model.fit(train_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6690f-b404-42e2-b0e7-639c5eabbadd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "future = overkill_model.make_future_dataframe(\n",
    "    train_neural, periods=len(val), n_historic_predictions=len(train_neural)\n",
    ")\n",
    "forecast = overkill_model.predict(future)[-len(val) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da4dbb8-eb90-431c-a65e-85ae5797b986",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0323f185-23e3-4f1d-bed3-c6c8e897c56b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot prophet's prediction\n",
    "neural_plot = [\n",
    "    go.Scatter(\n",
    "        x=forecast.ds, y=forecast.yhat1, mode=\"lines\", name=\"predicted_neural_prophet\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Display\n",
    "fig = go.Figure(data=base_plots + prediction_plots + neural_plot + prophet_plot)\n",
    "fig.update_layout(title=\"Forecasting in action (part 2) ðŸš€\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc6730-172d-46e6-8cb8-1e16d01528c5",
   "metadata": {},
   "source": [
    "Looks pretty similar, right? Hard to tell if we gained anything. What does the data tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7610d-f01c-471d-8428-5d3f37479a0d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results[\"Neural Prophet\"] = forecast_metrics(val.temperature, forecast.yhat1)\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e820f-0144-4d40-b258-94c4c0323852",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_metrics(results_df, baseline=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d25b2d-de0a-47ee-b0eb-3c0d5715bc41",
   "metadata": {},
   "source": [
    "You'll have to zoom in again, but it looks like we reduced our error yet a little more. Worth it? Depends on the time and compute we have at hand. The AutoARIMA model was actually quite expensive on both fronts. Prophet, in comparison, did fairly well! NeuralProphet did even better, but took a while longer to fit. Use the right tool for the right job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b481a6-41ae-4c2a-9662-6307bcd3ae0b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: We'll go with Neural Prophet -- package the model (to pickle?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp_env_ws",
   "language": "python",
   "name": "temp_env_ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
